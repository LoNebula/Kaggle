{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### CSIRO - Image2Biomass Prediction\nURL: https://www.kaggle.com/competitions/csiro-biomass/overview","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:56.691396Z","iopub.execute_input":"2025-11-18T01:03:56.692118Z","iopub.status.idle":"2025-11-18T01:03:57.091586Z","shell.execute_reply.started":"2025-11-18T01:03:56.692091Z","shell.execute_reply":"2025-11-18T01:03:57.090773Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Architecture\n\n```mermaid\ngraph LR\n    LoadData --> Preprocess\n    Preprocess --> ImageFeatures[\"Image Features Extraction (CNN)\"]\n    ImageFeatures --> TabularFeaturePrep[\"Tabular Feature preparation\"]\n    TabularFeaturePrep[\"Tabular Feature preparation\"] --> FeatureCombination[\"Feature combination\"]\n    FeatureCombination --> LightGBM\n    LightGBM --> Inference\n```","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor, log_evaluation\nfrom torchvision import models, transforms\nfrom PIL import Image\nfrom pathlib import Path\n\nprint(torch.cuda.is_available())\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:57.092695Z","iopub.execute_input":"2025-11-18T01:03:57.092909Z","iopub.status.idle":"2025-11-18T01:03:57.097868Z","shell.execute_reply.started":"2025-11-18T01:03:57.092893Z","shell.execute_reply":"2025-11-18T01:03:57.097184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# data import\ntrain_df = pd.read_csv('/kaggle/input/csiro-biomass/train.csv')\ntest_df = pd.read_csv('/kaggle/input/csiro-biomass/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/csiro-biomass/sample_submission.csv')\ntrain_df.head(6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:57.098625Z","iopub.execute_input":"2025-11-18T01:03:57.098917Z","iopub.status.idle":"2025-11-18T01:03:57.129742Z","shell.execute_reply.started":"2025-11-18T01:03:57.098900Z","shell.execute_reply":"2025-11-18T01:03:57.129182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# data check\ntrain_df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:57.130954Z","iopub.execute_input":"2025-11-18T01:03:57.131361Z","iopub.status.idle":"2025-11-18T01:03:57.137607Z","shell.execute_reply.started":"2025-11-18T01:03:57.131339Z","shell.execute_reply":"2025-11-18T01:03:57.136787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clover_g = train_df[train_df['target_name'] == 'Dry_Clover_g']\nclover_g.head(6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:57.138352Z","iopub.execute_input":"2025-11-18T01:03:57.138603Z","iopub.status.idle":"2025-11-18T01:03:57.159135Z","shell.execute_reply.started":"2025-11-18T01:03:57.138578Z","shell.execute_reply":"2025-11-18T01:03:57.158563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_cols = [c for c in train_df.columns if c not in ['sample_id', 'image_path','Sampling_Date', 'Sampling_Date', 'State', 'Species', 'target_name']]\n\nfeature_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:57.159838Z","iopub.execute_input":"2025-11-18T01:03:57.160080Z","iopub.status.idle":"2025-11-18T01:03:57.175507Z","shell.execute_reply.started":"2025-11-18T01:03:57.160065Z","shell.execute_reply":"2025-11-18T01:03:57.174880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axes = plt.subplots(len(feature_cols), 1, figsize=(6, 3 * len(feature_cols)), sharex=False)\n\nfor ax, col in zip(axes, feature_cols):\n    train_df[col].plot.hist(ax=ax, bins=40, color=\"steelblue\", alpha=0.75)\n    ax.set_title(f\"{col} histogram\")\n    ax.set_xlabel(\"biomass\")\n    ax.set_ylabel(\"count\")\n\nplt.tight_layout()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:57.176121Z","iopub.execute_input":"2025-11-18T01:03:57.176564Z","iopub.status.idle":"2025-11-18T01:03:57.869452Z","shell.execute_reply.started":"2025-11-18T01:03:57.176546Z","shell.execute_reply":"2025-11-18T01:03:57.868843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['sample_id'].dtype","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:57.870139Z","iopub.execute_input":"2025-11-18T01:03:57.870356Z","iopub.status.idle":"2025-11-18T01:03:57.875287Z","shell.execute_reply.started":"2025-11-18T01:03:57.870332Z","shell.execute_reply":"2025-11-18T01:03:57.874577Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:57.876177Z","iopub.execute_input":"2025-11-18T01:03:57.876882Z","iopub.status.idle":"2025-11-18T01:03:57.902119Z","shell.execute_reply.started":"2025-11-18T01:03:57.876863Z","shell.execute_reply":"2025-11-18T01:03:57.901534Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[\"Sampling_Date\"] = pd.to_datetime(train_df[\"Sampling_Date\"], format=\"%Y/%m/%d\")\n\ntrain_df[\"year\"] = train_df[\"Sampling_Date\"].dt.year\ntrain_df[\"month\"] = train_df[\"Sampling_Date\"].dt.month\ntrain_df[\"day\"] = train_df[\"Sampling_Date\"].dt.day\n\ntrain_df[[\"year\", \"month\", \"day\"]].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:57.903963Z","iopub.execute_input":"2025-11-18T01:03:57.904197Z","iopub.status.idle":"2025-11-18T01:03:57.922617Z","shell.execute_reply.started":"2025-11-18T01:03:57.904184Z","shell.execute_reply":"2025-11-18T01:03:57.922011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:57.923283Z","iopub.execute_input":"2025-11-18T01:03:57.923804Z","iopub.status.idle":"2025-11-18T01:03:57.941805Z","shell.execute_reply.started":"2025-11-18T01:03:57.923787Z","shell.execute_reply":"2025-11-18T01:03:57.941176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tabular_feats = [\"Pre_GSHH_NDVI\", \"Height_Ave_cm\", \"State\", \"Species\", \"year\", \"month\", \"day\"]\n\ntarget_col = \"target\"\n\n# Categorical features\ncat_cols = [\"State\", \"Species\"]\ntrain_df[cat_cols] = train_df[cat_cols].astype(\"category\")\n\nX = train_df[tabular_feats]\ny = train_df[target_col]\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LGBMRegressor(\n    n_estimators=300,\n    learning_rate=0.01,\n    max_depth=-1,\n    num_leaves=20,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42,\n)\n\nmodel.fit(\n    X_train,\n    y_train,\n    eval_set=[(X_val, y_val)],\n    eval_metric=\"rmse\",\n    categorical_feature=cat_cols,\n    callbacks=[log_evaluation(period=10)],\n)\n\n# predict on test set\nvalid_pred = model.predict(X_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:57.942537Z","iopub.execute_input":"2025-11-18T01:03:57.942800Z","iopub.status.idle":"2025-11-18T01:03:58.103987Z","shell.execute_reply.started":"2025-11-18T01:03:57.942783Z","shell.execute_reply":"2025-11-18T01:03:58.103248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ImageNet\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# pretrained model\nbackbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\nfeature_extractor = torch.nn.Sequential(*(list(backbone.children())[:-1])).to(device)\nfeature_extractor.eval()\n\ndef extract_features(img_path: Path) -> torch.Tensor:\n    img = Image.open(img_path).convert(\"RGB\")\n    x = transform(img).unsqueeze(0).to(device)\n    with torch.no_grad():\n        feat = feature_extractor(x)\n    return feat.detach().cpu().flatten()\n\ndef add_cnn_features(df, img_root: Path):\n    feats = []\n    for p in df[\"image_path\"]:\n        f = extract_features(img_root / p)\n        feats.append(f.numpy())\n    feat_df = pd.DataFrame(feats, columns=[f\"cnn_{i}\" for i in range(f.numel())])\n    return pd.concat([df.reset_index(drop=True), feat_df], axis=1)\n\n# Path to train and test images\nimg_root = Path(\"/kaggle/input/csiro-biomass\")\n\ntrain_with_feat = add_cnn_features(train_df, img_root)\ntest_with_feat = add_cnn_features(test_df, img_root)\n\ncnn_feats = [c for c in train_with_feat.columns if c.startswith(\"cnn_\")]\nfeats = cnn_feats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:03:58.104758Z","iopub.execute_input":"2025-11-18T01:03:58.105065Z","iopub.status.idle":"2025-11-18T01:05:38.399983Z","shell.execute_reply.started":"2025-11-18T01:03:58.105047Z","shell.execute_reply":"2025-11-18T01:05:38.399135Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:05:38.400832Z","iopub.execute_input":"2025-11-18T01:05:38.401177Z","iopub.status.idle":"2025-11-18T01:05:38.408642Z","shell.execute_reply.started":"2025-11-18T01:05:38.401148Z","shell.execute_reply":"2025-11-18T01:05:38.408013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train_with_feat[feats]\ny = train_with_feat[\"target\"]\nmodel.fit(X, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:05:55.686708Z","iopub.execute_input":"2025-11-18T01:05:55.687251Z","iopub.status.idle":"2025-11-18T01:06:00.204352Z","shell.execute_reply.started":"2025-11-18T01:05:55.687228Z","shell.execute_reply":"2025-11-18T01:06:00.203593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"set(feats) - set(test_with_feat.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:06:05.473517Z","iopub.execute_input":"2025-11-18T01:06:05.474022Z","iopub.status.idle":"2025-11-18T01:06:05.479165Z","shell.execute_reply.started":"2025-11-18T01:06:05.474000Z","shell.execute_reply":"2025-11-18T01:06:05.478487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_pred = model.predict(test_with_feat[feats])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:06:07.971844Z","iopub.execute_input":"2025-11-18T01:06:07.972449Z","iopub.status.idle":"2025-11-18T01:06:07.979900Z","shell.execute_reply.started":"2025-11-18T01:06:07.972423Z","shell.execute_reply":"2025-11-18T01:06:07.978958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create submission\nsub = test_df[[\"sample_id\"]].copy()\nsub[\"target\"] = test_pred\nsub.to_csv(\"/kaggle/working/submission.csv\", index=False)\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T01:06:10.417440Z","iopub.execute_input":"2025-11-18T01:06:10.418113Z","iopub.status.idle":"2025-11-18T01:06:10.424688Z","shell.execute_reply.started":"2025-11-18T01:06:10.418090Z","shell.execute_reply":"2025-11-18T01:06:10.423968Z"}},"outputs":[],"execution_count":null}]}