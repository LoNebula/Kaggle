{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### CSIRO - Image2Biomass Prediction\nURL: https://www.kaggle.com/competitions/csiro-biomass/overview","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nprint(torch.cuda.is_available())\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T10:53:12.645675Z","iopub.execute_input":"2026-01-13T10:53:12.645862Z","iopub.status.idle":"2026-01-13T10:53:14.264430Z","shell.execute_reply.started":"2026-01-13T10:53:12.645845Z","shell.execute_reply":"2026-01-13T10:53:14.263259Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/3540599587.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"],"ename":"NameError","evalue":"name 'torch' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"# data import\ntrain_df = pd.read_csv('/kaggle/input/csiro-biomass/train.csv')\ntest_df = pd.read_csv('/kaggle/input/csiro-biomass/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/csiro-biomass/sample_submission.csv')\ntrain_img = torch.utils.data.DataLoader('/kaggle/input/csiro-biomass/train')\ntrain_df = pd.DataFrame(train_df)\ntest_df = pd.DataFrame(test_df)\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T10:53:14.264908Z","iopub.status.idle":"2026-01-13T10:53:14.265157Z","shell.execute_reply.started":"2026-01-13T10:53:14.265027Z","shell.execute_reply":"2026-01-13T10:53:14.265038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# extract target columns\ny_train = torch.tensor(train_df['target'].values.astype(np.float32))\ny_train = y_train.unsqueeze(1)\n\ny_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T10:53:14.266531Z","iopub.status.idle":"2026-01-13T10:53:14.266748Z","shell.execute_reply.started":"2026-01-13T10:53:14.266647Z","shell.execute_reply":"2026-01-13T10:53:14.266658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom PIL import Image\n\nclass ImageFeatureExtractor:\n    def __init__(self, model_name='resnet50'):\n        # select model\n        if model_name == 'resnet50':\n            model = models.resnet50(pretrained=True)\n            # remove last layer\n            self.encoder = torch.nn.Sequential(*list(model.children())[:-1])\n            self.feature_dim = 2048\n\n        elif model_name == 'resnet18':\n            model = models.resnet18(pretrained=True)\n            self.encoder = torch.nn.Sequential(*list(model.children())[:-1])\n            self.feature_dim = 512\n\n        elif model_name == 'efficientnet_b0':\n            model = models.efficientnet_b0(pretrained=True)\n            self.encoder = model.features\n            self.encoderl.add_module('avgpool', torch.nn.AdaptiveAvgPool2d(1))\n            self.feature_dim = 1280\n\n        self.encoder.eval()\n\n        # preprocessing\n        self.transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225]\n            )\n        ])\n\n    def extract_features(self, image_path):\n        # load image\n        image = Image.open(image_path).convert('RGB')\n\n        # preprocessing\n        input_tensor = self.transform(image).unsqueeze(0)\n\n        # extrach feature\n        with torch.no_grad():\n            features = self.encoder(input_tensor)\n\n        # flatten and numpy\n        features = features.squeeze().numpy()\n\n        return features\n\n    def extract_features_dict(self, image_path, prefix='img'):\n        # return dict\n        features = self.extract_features(image_path)\n\n        # convert dict\n        features_dict = {\n            f'{prefix}_feat_{i}': float(val)\n            for i, val in enumerate(features)\n        }\n\n        return features_dict\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T10:53:14.268202Z","iopub.status.idle":"2026-01-13T10:53:14.268443Z","shell.execute_reply.started":"2026-01-13T10:53:14.268330Z","shell.execute_reply":"2026-01-13T10:53:14.268344Z"}},"outputs":[],"execution_count":null}]}