{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93047dca",
   "metadata": {},
   "source": [
    "### CSIRO - Image2Biomass Prediction\n",
    "URL: https://www.kaggle.com/competitions/csiro-biomass/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf5de9b",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    LoadData --> Preprocess\n",
    "    Preprocess --> ImageFeatures[\"Image Features Extraction (CNN)\"]\n",
    "    ImageFeatures --> TabularFeaturePrep[\"Tabular Feature preparation\"]\n",
    "    TabularFeaturePrep[\"Tabular Feature preparation\"] --> FeatureCombination[\"Feature combination\"]\n",
    "    FeatureCombination --> LightGBM\n",
    "    LightGBM --> Inference\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor, log_evaluation\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "train_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbfb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data check\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dafd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "clover_g = train_df[train_df['target_name'] == 'Dry_Clover_g']\n",
    "clover_g.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e717d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in train_df.columns if c not in ['sample_id', 'image_path','Sampling_Date', 'Sampling_Date', 'State', 'Species', 'target_name']]\n",
    "\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(feature_cols), 1, figsize=(6, 3 * len(feature_cols)), sharex=False)\n",
    "\n",
    "for ax, col in zip(axes, feature_cols):\n",
    "    train_df[col].plot.hist(ax=ax, bins=40, color=\"steelblue\", alpha=0.75)\n",
    "    ax.set_title(f\"{col} histogram\")\n",
    "    ax.set_xlabel(\"biomass\")\n",
    "    ax.set_ylabel(\"count\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c19de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sample_id'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70af804",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Sampling_Date\"] = pd.to_datetime(train_df[\"Sampling_Date\"], format=\"%Y/%m/%d\")\n",
    "\n",
    "train_df[\"year\"] = train_df[\"Sampling_Date\"].dt.year\n",
    "train_df[\"month\"] = train_df[\"Sampling_Date\"].dt.month\n",
    "train_df[\"day\"] = train_df[\"Sampling_Date\"].dt.day\n",
    "\n",
    "train_df[[\"year\", \"month\", \"day\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91651f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b88da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_feats = [\"Pre_GSHH_NDVI\", \"Height_Ave_cm\", \"State\", \"Species\", \"year\", \"month\", \"day\"]\n",
    "\n",
    "target_col = \"target\"\n",
    "\n",
    "# Categorical features\n",
    "cat_cols = [\"State\", \"Species\"]\n",
    "train_df[cat_cols] = train_df[cat_cols].astype(\"category\")\n",
    "\n",
    "X = train_df[tabular_feats]\n",
    "y = train_df[target_col]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LGBMRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=-1,\n",
    "    num_leaves=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"rmse\",\n",
    "    categorical_feature=cat_cols,\n",
    "    callbacks=[log_evaluation(period=10)],\n",
    ")\n",
    "\n",
    "# predict on test set\n",
    "valid_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22465856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pretrained model\n",
    "backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "feature_extractor = torch.nn.Sequential(*(list(backbone.children())[:-1])).to(device)\n",
    "feature_extractor.eval()\n",
    "\n",
    "def extract_features(img_path: Path) -> torch.Tensor:\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = feature_extractor(x)\n",
    "    return feat.detach().cpu().flatten()\n",
    "\n",
    "def add_cnn_features(df, img_root: Path):\n",
    "    feats = []\n",
    "    for p in df[\"image_path\"]:\n",
    "        f = extract_features(img_root / p)\n",
    "        feats.append(f.numpy())\n",
    "    feat_df = pd.DataFrame(feats, columns=[f\"cnn_{i}\" for i in range(f.numel())])\n",
    "    return pd.concat([df.reset_index(drop=True), feat_df], axis=1)\n",
    "\n",
    "# Path to train and test images\n",
    "img_root = Path(\"data\")\n",
    "\n",
    "train_with_feat = add_cnn_features(train_df, img_root)\n",
    "test_with_feat = add_cnn_features(test_df, img_root)\n",
    "\n",
    "cnn_feats = [c for c in train_with_feat.columns if c.startswith(\"cnn_\")]\n",
    "feats = tabular_feats + cnn_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc67c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50615dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_with_feat[feats]\n",
    "y = train_with_feat[target_col]\n",
    "model.fit(X, y, categorical_feature=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63146524",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_feat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7299f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(feats) - set(test_with_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df にも年月日を追加する\n",
    "test_df[\"Sampling_Date\"] = pd.to_datetime(test_df[\"Sampling_Date\"], format=\"%Y/%m/%d\")\n",
    "test_df[\"year\"] = test_df[\"Sampling_Date\"].dt.year\n",
    "test_df[\"month\"] = test_df[\"Sampling_Date\"].dt.month\n",
    "test_df[\"day\"] = test_df[\"Sampling_Date\"].dt.day\n",
    "\n",
    "# カテゴリ型も train と合わせる\n",
    "test_df[cat_cols] = test_df[cat_cols].astype(\"category\")\n",
    "\n",
    "test_with_feat = add_cnn_features(test_df, img_root)\n",
    "test_pred = model.predict(test_with_feat[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b23a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "sub = test_df[[\"sample_id\"]].copy()\n",
    "sub[\"target\"] = test_pred\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
