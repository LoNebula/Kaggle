{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccc20070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caa9c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "from transformers import AutoConfig, ViTModel  # \"transfomers\" → \"transformers\" に修正\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d7b4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_solutions = json.loads(\"/kaggle/input/arc-prize-2025/arc-agi_training_solutions.json\")\n",
    "# train_challenges = json.loads(\"/kaggle/input/arc-prize-2025/arc-agi_training_challenges.json\")\n",
    "# eval_solutions = json.loads(\"/kaggle/input/arc-prize-2025/arc-agi_evaluation_solutions.json\")\n",
    "# eval_challenges = json.loads(\"/kaggle/input/arc-prize-2025/arc-agi_evaluation_challenges.json\")\n",
    "\n",
    "# file_path\n",
    "train_solutions = json.loads(open(\"data/ARC_Prize_2025/arc-agi_training_solutions.json\").read())\n",
    "train_challenges = json.loads(open(\"data/ARC_Prize_2025/arc-agi_training_challenges.json\").read())\n",
    "eval_solutions = json.loads(open(\"data/ARC_Prize_2025/arc-agi_evaluation_solutions.json\").read())\n",
    "eval_challenges = json.loads(open(\"data/ARC_Prize_2025/arc-agi_evaluation_challenges.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6005ff9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 120 120\n",
      "head of train_solutions\n",
      "[[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\n",
      "head of train_challenges\n",
      "{'train': [{'input': [[7, 9], [4, 3]], 'output': [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]}, {'input': [[8, 6], [6, 4]], 'output': [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]}], 'test': [{'input': [[3, 2], [7, 8]]}]}\n",
      "dict_keys(['train', 'test'])\n",
      "[{'input': [[7, 9], [4, 3]], 'output': [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]}, {'input': [[8, 6], [6, 4]], 'output': [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]}]\n",
      "{'input': [[7, 9], [4, 3]], 'output': [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]}\n",
      "[[7, 9], [4, 3]]\n",
      "[[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]\n",
      "[7, 9]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_solutions), len(train_challenges), len(eval_solutions), len(eval_challenges))\n",
    "\n",
    "print(\"head of train_solutions\")\n",
    "print(train_solutions[\"00576224\"])\n",
    "print(\"head of train_challenges\")\n",
    "print(train_challenges[\"00576224\"])\n",
    "print(train_challenges[\"00576224\"].keys())\n",
    "print(train_challenges[\"00576224\"][\"train\"])\n",
    "print(train_challenges[\"00576224\"][\"train\"][0])\n",
    "print(train_challenges[\"00576224\"][\"train\"][0][\"input\"])\n",
    "print(train_challenges[\"00576224\"][\"train\"][0][\"output\"])\n",
    "print(train_challenges[\"00576224\"][\"train\"][0][\"input\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474a670",
   "metadata": {},
   "source": [
    "- Transformers\n",
    "- Graph Neural Networks\n",
    "- Program Synthesis / Sysbolic AI\n",
    "- Neuro-Symbolic AI\n",
    "\n",
    "1. First of all, CNN + Transformers is the base line.\n",
    "2. Second of all, Vision Transformer + Attension.\n",
    "3. Third of all, Graph Neural Network.\n",
    "4. Last of all, Neuro-Symbolic like hybrid approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8d033a",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da926741",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'end' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m transformer_model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mTransformer(nhead\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, num_encoder_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tensordict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_challenges):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, tensordict[\u001b[43mend\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'end' is not defined"
     ]
    }
   ],
   "source": [
    "transformer_model = nn.Transformer(nhead=8, num_encoder_layers=6)\n",
    "for i, tensordict in enumerate(train_challenges):\n",
    "    print(i, tensordict)\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6b8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
